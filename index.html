<!DOCTYPE html>
<html>

<head>
  <title>Double Y: Tropical storm damage detection</title>
  <link rel="icon" type="image/png" href="static/images/EY Satelite Image.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <meta name="description" content="Double Y: Tropical storm damage detection">
  <meta property="og:title" content="Double Y: Tropical storm damage detection"/>
  <meta property="og:description" content="AUTOMATING COASTAL VULNERABILITY ASSESSMENT"/>
  <meta property="og:url" content="https://github.com/Double-Y-EY-Challenge-2024"/>
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Post-Storm Event Assessment: Damaged Building Detection 
              and Classification</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/wongyijie/" target="_blank">Yi Jie WONG</a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/yinloonkhor/" target="_blank">Yin Loon KHOR</a>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/ziweiliu2023/" target="_blank">Ziwei LIU</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><strong>Group Name:</strong> Double-Y | <strong>Public
                  Leaderboard:</strong> 11/222 (Top 5%)<br>
                <a href="https://challenge.ey.com/challenges/tropical-cyclone-damage-assessment-lrrno2xm">EY Open
                  Science Data Challenge Program 2024</a>
              </span>

              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">

                <!-- PDF -->
                <span class="link-block">
                  <a href="static/pdfs/Team Double Y - Approach Document.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/Double-Y-EY-Challenge-2024/EY-challenge-2024" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Source Code</span>
                  </a>
                </span>

                <!-- Best model -->
                <span class="link-block">
                  <a href="https://github.com/Double-Y-EY-Challenge-2024/EY-challenge-2024/blob/main/best-trained-model.pt"
                    target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Best Model</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


<!-- Teaser GIF -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/heatmaps/movie.gif" alt="Inference samples predicted by our trained model.">
      <h2 class="subtitle">
        Geospatial analysis.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser GIF -->



  <!-- Summary -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Summary</h2>
          <div class="content has-text-justified">
            <p> The 2024 EY Open Science Data challenge focuses on coastal resilience and climate change. Participants 
              will use high-resolution satellite datasets to build predictive models to help vulnerable coastal 
              communities adapt to evolving conditions and recover from extreme climate events. These solutions will 
              result in new and innovative ideas designed to increase the impact of data for societal benefit.
            </p>

            <p>Despite these challenges, we are immensely grateful, and our collective efforts enabled us to achieve a
              final mAP50 score of 0.51, placing us in the top 5% in the public leaderboard.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Competition Overview -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Competition Overview</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>This overview is adapted from the original competition description.</p>
          <p><strong>1. Objective:</strong> The objective of the challenge is to develop a machine learning model
            capable of identifying and detecting "damaged" and "undamaged" coastal infrastructure, including residential
            and commercial buildings, affected by natural disasters such as hurricanes and cyclones. Participants will be 
            provided with pre- and post-cyclone satellite images of an area impacted by Hurricane Maria in 2017. The task 
            is to build a machine learning model capable of detecting four different types of objects in the satellite 
            images of cyclone-affected areas:</p>
          <ul>
            <li>Undamaged residential buildings</li>
            <li>Damaged residential buildings</li>
            <li>Undamaged commercial buildings</li>
            <li>Damaged commercial buildings</li>
          </ul>
          <p><strong>2. Dataset Used:</strong></p>
          <p><strong>Mandatory dataset:</strong></p>
          <ul>
            <li>High-resolution panchromatic satellite images before and after a tropical cyclone: Maxar GeoEye-1
              (optical)</li>
          </ul>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- Competition Overview -->

  <!-- Key Challenges -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Key Challenges</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>
            <strong>1. Dataset Collection:</strong> Manually annotating all four classes in the provided high-resolution
            satellite dataset from Maxar's GEO-1 mission, covering an area of 327 sq.km of San Juan, Puerto Rico, is a
            time-consuming task. With only one month for the competition duration, this task poses significant
            challenges in terms of time and energy allocation.
          </p>
          <p>
            <strong>2. Imbalanced Dataset:</strong> The dataset comprises four classes of building damages: undamaged
            commercial buildings, undamaged residential buildings, damaged commercial buildings, and damaged residential
            buildings. Our analysis reveals that damaged classes are underrepresented compared to undamaged ones.
            Additionally, residential buildings are more common than commercial buildings. This imbalance can introduce
            bias and affect the performance of our model, particularly towards the majority class.
          </p>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- Key Challenges -->

  
  <!-- Methodology Overview -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3" style="white-space: nowrap;">Methodology Overview</h2>
      <div class="content has-text-justified">
        <div style="text-align: center;">
          <img src="static/images/Team Double Y - Methodology.jpg" alt="PrepareData" width="820">
          <p class="caption" style="width: 100%; text-align: center;"><b>Figure 1. Overview of the proposed methodology.</b><br>
            Workflow illustrating the complete process from data acquisition to model training.</p>
        </div>
      </div>
      <br>
    </div>
  </div>
  <!-- End methodology overview-->

  
  <!-- Model -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Model</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>
            The goal of Phase 1 is to identify and detect “damaged” and “undamaged” coastal infrastructure, which is an  
            object detection task. To tackle this challenge, our team has opted for Ultralytics <strong>YOLOv8</strong>, 
            one of the state-of-the-art (SOTA) object detection models renowned for its speed and accuracy. Despite the availability 
            of competitors like YOLOv9, we prefer Ultralytics YOLOv8 for its user-friendliness and well-documented workflows 
            that streamline training and deployment. We choose the smallest YOLOv8 - <strong>YOLOv8n</strong>, since it is 
            <strong>unwise to use larger model when dealing with limited dataset</strong>, as it may lead to overfitting. 
            Given more time, we would explore other YOLOv8 version and other SOTA models when we have a bigger dataset. 
          </p>

          <p>          
            Meanwhile, our empirical study revealed that the main influencing factor on the detection accuracy is 
            the quantity and quality of the annotated dataset. Hence, we argue that the main focus of the challenge 
            should be data annotation. We provide details on how we built our training dataset in the next section.            
          </p>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- Model -->

  
  <!-- Submission Experiments Table -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Submission Experiment</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>We conducted a comprehensive series of experiments, submitting a total of 30 entries. Here are select
            highlights:</p>
          <table class="table is-bordered is-hoverable">
            <thead>
              <tr>
                <th>Setup</th>
                <th>Pretraining</th>
                <th>Crowdsourced Dataset</th>
                <th>Expert Dataset</th>
                <th>MLOps</th>
                <th>mAP</th>                      
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>A</td>
                <td>&#x2713;</td>
                <td></td>
                <td></td>
                <td></td>              
                <td>0.10</td>
              </tr>
              <tr>
                <td>B</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td></td>
                <td></td>              
                <td>0.44</td>
              </tr>
              <tr>
                <td>C</td>
                <td>&#x2713;</td>
                <td></td>
                <td>&#x2713;</td>
                <td></td>              
                <td>0.39</td>
              </tr>
              <tr>
                <td>D</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td></td>              
                <td>0.50</td>
              </tr>
              <tr>
                <td>E</td>
                <td></td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td></td>              
                <td>0.24</td>
              </tr>
              <tr>
                <td>F</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>
                <td>&#x2713;</td>              
                <td><b>0.51</b></td>
              </tr>                 
            </tbody>
          </table>

          <!--
          <p style="font-size: 12px;">Note: Class Ratio (Undamaged Residential Building : Damaged Residential Building :
            Undamaged Commercial Building : Damaged Commercial Building)</p>
          -->
          <p>Further experiments were conducted, including:</p>
          <ul style="list-style-type: none; padding-left: 0;">
            <li style="margin-bottom: 5px;"><strong>Setup A:</strong> 0.46 - We pretrained a YOLOv8n model using the 
              Puerto Rico dataset. Surprisingly, we achieved a mAP of 0.10 on the EY validation dataset, without any 
              manual annotation from our side!</li>
            <li style="margin-bottom: 5px;"><strong>Setup B:</strong> 0.46 - When fine-tuning the pretrained model on 
              the crowd-sourced dataset, we achieved an mAP of 0.44, which exceeds the completion threshold for this 
              challenge (mAP 0.40). </li>
            <li style="margin-bottom: 5px;"><strong>Setup C:</strong> 0.46 - When fine-tuning the pretrained model 
              directly on the Expert dataset, we can achieve an mAP of 0.39, despite the dataset containing only 28 
              unique data (84 after augmentation). This shows that the quality of data is equally important, if not 
              more important than the quantity of data.</li>
            <li style="margin-bottom: 5px;"><strong>Setup D:</strong> 0.46 - We initially fine-tune the pretrained 
              model using a large-scale crowd-sourced dataset to quickly warm it up. Subsequently, we fine-tune the 
              model on the expert dataset, which has more accurate labels. With this approach, we achieved a mAP of 
              0.50.</li>
            <li style="margin-bottom: 5px;"><strong>Setup E:</strong> 0.46 - We demonstrate that without pretraining, 
              the performance is not satisfying even when both the crowd-sourced and expert datasets are utilised, 
              only achieving mAP 0.24.</li>
            <li style="margin-bottom: 5px;"><strong>Setup F:</strong> 0.46 - Finally, we demonstrate that by employing 
              the proposed MLOps cycle, we can enhance the model’s mAP to 0.51. Notably, the sole human intervention 
              in this MLOps cycle involves verifying the self-labelled data using the baseline model from Setup E.</li>         
          </ul>
          <p>From these experiments, we can conclude that our submission scores are mainly contributed by the quality of
            the dataset. We managed to achieve the highest score of 0.48 solely from the dataset itself. Our focus was
            primarily on preparing the training dataset, with minimal time allocated to model development. Given more
            time, we would explore various training configurations, model backbones, and architectures. Additionally, we
            would enhance our synthetic image generation models and collect more diverse datasets to further improve our
            results.</p>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- End of Submission Experiments Table -->

  <!-- Conclusion -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Conclusion and Reflection</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>
            <strong>1. Dataset is all you need:</strong> It is evident that everything comes down to how we prepare the
            dataset for training a machine learning model. No matter how deep the neural networks are or how
            sophisticated the model is, if the dataset is of poor quality, our model will never be able to make accurate
            predictions. Our experiments have shown that with a quality dataset, achieving a minimum of 0.40 is
            possible, which is sufficient to meet the minimum requirement by EY for a certificate of completion. Our
            team spent most of the time annotating the dataset and preparing a high-quality dataset. Each label was
            cross-referenced with reliable sources using Google Maps, OpenStreetMap, and even Google 3D street view to
            determine the class for each building.
          </p>
          <p>
            <strong>2. Start with a small model:</strong> It is advisable to begin with a small model when embarking on
            a machine learning project. When selecting a model for training, starting with the smallest and lightest
            model is preferable before moving on to larger and heavier models. The complexity of a model depends on its
            parameters and the depth of its layers. By starting with a small model, we have more flexibility to expand
            further with larger models. Our best model is the small variant of YOLOv8, and although we attempted to
            train YOLOv8m and YOLOv8l, we were unable to surpass our small model. Please note that these findings are
            based on our experiments, and other teams may obtain different results.
          </p>
          <p>
            <strong>3. Not everything goes your way:</strong> Despite our efforts to address the imbalanced dataset by
            generating synthetic data with Stable Diffusion 2, the results did not meet our expectations. We anticipated
            that resolving the imbalance would lead to improved model performance, but this was not the case. Several
            factors may have contributed to this outcome, including insufficient training of the stable diffusion model
            to generate synthetic data resembling the actual dataset, lack of generalization in the model, and limited
            variation in the synthetic dataset. It is important to remember that machine learning involves
            experimentation. By continually experimenting with different settings, architectures, and approaches, we may
            eventually build a better model through trial, error, and continuous testing and monitoring.
          </p>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- Conclusion -->

  <!-- Logo Acknowledgment -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h4 class="title is-3" style="white-space: nowrap;">Technological Stack</h4>
      <div class="content has-text-justified">
        <div style="text-align: justify;">
          <p>
            <a href="https://github.com/ultralytics/ultralytics" target="_blank"><img
                src="static/icons/ultralyticsyolo-logo.svg" alt="ultralytics" style="width: 200px;"></a>
            <a href="https://roboflow.com/" target="_blank"><img
                src="static/icons/roboflow-logo.png" alt="roboflow" style="width: 200px;"></a>          
            <a href="https://pytorch.org/" target="_blank"><img src="static/icons/pytorch-logo.svg" alt="pytorch"
                style="width: 210px;"></a>        
            <a href="https://jupyter.org/" target="_blank"><img src="static/icons/jupyter-logo.png" alt="jupyter"
                style="width: 200px;"></a>              
            <a href="https://www.python.org/" target="_blank"><img src="static/icons/python-logo.svg" alt="python"
                style="width: 200px;"></a>  
          </p>
        </div>
      </div>
      <br><br>
    </div>
  </div>
  <!-- Logo Acknowledgment -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Default Statcounter code for EY project website
http://EY-Groupie2024WG.github.io -->
  <script type="text/javascript">
    var sc_project = 12976265;
    var sc_invisible = 1;
    var sc_security = "c70be6f1"; 
  </script>
  <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript>
    <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
          class="statcounter" src="https://c.statcounter.com/12976265/0/c70be6f1/1/" alt="Web Analytics"
          referrerPolicy="no-referrer-when-downgrade"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

</body>

</html>
